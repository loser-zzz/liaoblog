[{"title":"什么叫MYSQl事务以及特性","date":"2023-11-29T16:00:00.000Z","url":"/2023/11/30/MYSQL/%E4%BB%80%E4%B9%88%E5%8F%ABMYSQl%E4%BA%8B%E5%8A%A1%E4%BB%A5%E5%8F%8A%E7%89%B9%E6%80%A7/","tags":[["mysql","/tags/mysql/"]],"categories":[["MYSQL","/categories/MYSQL/"]],"content":"什么叫MYSQl事务以及特性引言 事务：是数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作；这些操作作为一个整体一起向系统提交，要么都执行、要么都不执行；事务是一组不可再分割的操作集合（工作逻辑单元）； 事务的四大特性：原子性，一致性，隔离性，持久性。 步骤 原子性 ：事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做 一致性 ：事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。 隔离性 ：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。 持续性 ：也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。 "},{"title":"PHP使用ffmpeg截取视频第一帧做封面","date":"2023-11-29T16:00:00.000Z","url":"/2023/11/30/PHP/PHP%E4%BD%BF%E7%94%A8ffmpeg%E6%88%AA%E5%8F%96%E8%A7%86%E9%A2%91%E7%AC%AC%E4%B8%80%E5%B8%A7%E5%81%9A%E5%B0%81%E9%9D%A2/","tags":[["PHP","/tags/PHP/"],["ffmpeg","/tags/ffmpeg/"]],"categories":[["PHP","/categories/PHP/"]],"content":"PHP使用ffmpeg截取视频第一帧做封面引言 近期有个项目需要用到截取视频封面的第一帧作为视频的封面，最先是使用js的canvas处理，发现兼容性太差，局限也很多，然后不得不后台进行处理。 查找了一下资料和问了一波网友，得出介绍有ffmpeg，opencv。opencv呢是py的，我不会，然后被嘲讽一波。真是尴尬。不得不选用ffmpeg进行视频处理。 步骤 先安装ffmpeg： 出现以下错误就是 缺失yasm 扩展： 装上 yasm: 装完 就继续： 成功装完了就开始代码了。 这里有两种方式 就是直接采用PHP的exec()函数 运行ffmpeg 进行视频截取。 是用第三方的类库这个是封装好的面向对象的类库。 我这里采用的是第一种方法。上码： 然后就结束了。有几点需要注意: ffmpeg只能截取mp4格式的视频文件 命令行函数 路径参数 最好都是绝对路径。 "},{"title":"php验证上传的图片是否包含东西","date":"2023-11-29T16:00:00.000Z","url":"/2023/11/30/PHP/php%E9%AA%8C%E8%AF%81%E4%B8%8A%E4%BC%A0%E7%9A%84%E5%9B%BE%E7%89%87%E6%98%AF%E5%90%A6%E5%8C%85%E5%90%AB%E4%B8%9C%E8%A5%BF/","tags":[["PHP","/tags/PHP/"]],"categories":[["PHP","/categories/PHP/"]],"content":"php验证上传的图片是否包含东西引言 最近忙项目，一套curd下来暂时也没学到什么东西。 写这个文章也是记录一下平时和真*大佬吹牛逼的时候知道的一个小方法。 有些人特坏，上传图片的时候要恶意包含一些奇奇怪怪的东西，防不胜防。 步骤 代码： "},{"title":"关于laravel日志文件权限错误","date":"2023-11-29T16:00:00.000Z","url":"/2023/11/30/PHP/%E5%85%B3%E4%BA%8Elaravel%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E9%94%99%E8%AF%AF/","tags":[["PHP","/tags/PHP/"],["laravel","/tags/laravel/"]],"categories":[["PHP","/categories/PHP/"]],"content":"关于laravel日志文件权限错误引言 场景：laravel在Nginx运行的时候产生的日志文件，定时任务也产生了日志文件，在某些时候会报权限错误（could not be opened in append mode: failed to open stream: Permission denied）。 步骤 这个问题在技术群里面有人提到过，觉得挺有意思的，打算复现一下场景。 准备好了laravel6.0，虚拟机一台（centos7.8），宝塔的集成环境。 创建一个日志写入的控制器: 编辑TestController控制器，添加以下方法。 添加路由: 访问test方法，使其产生日志： 创建一个Artisan命令： 编辑TestLog文件： 进行命令测试，查看是否能顺利的产生日志文件： 这个时候是顺利的写入了文件： 这个日志文件是由Nginx先产生的，所以日志文件是属于www的。 写个定时任务： 这个时候的日志写入是正常的，删除掉之前Nginx生成的日志，使用定时任务来生成日志，等定时任务生成日志文件之后，再访问test方法，就会出现以下错误： 查看现在的日志文件（定时任务产生的）： 由此得知产生的日志文件所属不同而导致权限不足，没办法写入文件，比如crontab这种命令在没有指定用户执行的情况下默认是root执行的，所以在涉及到文件写入的时候要默认统一用户执行。 所以上面的问题解决方法，先删除之前创建的定时任务和删除日志文件。 创建新的定时任务，并制定用户执行： 查询定时任务的时候，也要带上用户信息去查询： 一分钟后，定时任务自动会创建一个日志文件，所属www的： 再去访问test方法你会发现没有报错了。 所以涉及共用文件的时候最好统一用户去执行操作，不然就会出现权限问题。 "},{"title":"laravel在Windows系统下laradock运行响应延时解决方案","date":"2023-11-29T16:00:00.000Z","url":"/2023/11/30/%E6%9D%82%E9%A1%B9/laravel%E5%9C%A8Windows%20%E7%B3%BB%E7%BB%9F%E4%B8%8Blaradock%E8%BF%90%E8%A1%8C%E5%93%8D%E5%BA%94%E5%BB%B6%E6%97%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","tags":[["laravel","/tags/laravel/"],["laradock","/tags/laradock/"],["docker","/tags/docker/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"laravel在Windows系统下laradock运行响应延时解决方案引言 早期的windows下的开发环境是用PHPstudy进行集成环境开发，但是随着技术的上涨，了解的东西越多，有些东西只能在Linux下面进行开发，加上合适的机会使用上了docker。 步骤 用docker hub 面板加上laradock环境一把梭，问题也来了。Laravel在laradock上面响应很慢。 查询资料说是由docker 共享目录的 io 慢造成的，导致响应时间很长。 解决方法：在docker hub设置页面，Settings -&gt; General -&gt; 把 use the wsl2 based engine 的勾选取消掉。点击apply &amp; restart。 注意-注意-注意：勾选重启后，之前安装好的镜像都会丢失，需要重新安装。 "},{"title":"Nginx负载均衡","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/NGINX/Nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","tags":[["Nginx","/tags/Nginx/"]],"categories":[["Nginx","/categories/Nginx/"]],"content":"Nginx负载均衡步骤 什么是负载均衡？。 负载均衡简单来说就是多台计算机分摊工作任务造成的压力。 应用场景是什么？ 例如：多人访问同一台服务器的时候，可以分别指向访问到其他备份服务器。再比如说，一个地铁站有A和B两个出口，有很多人都往A出口挤，这时候有个地铁工作人员说B出口没人，来一部分人走B出口，这个时候工作人员起到了负载均衡的作用。 负载均衡的分类，这里需要了解一下OSI七层模型: 二层负载均衡。 三层负载均衡。 四层负载均衡。 七层负载均衡。 注：比较常见的是四层负载均衡（LVS），七层负载均衡（Nginx）。 负载均衡的算法： 静态算法：轮询，比率，优先权。 动态算法：最少连接方式，最快模式，等。 以上就是负载均衡的一些介绍，下面是介绍如何用Nginx做负载均衡。 nginx的负载均衡常用有几种模式（不包括第三方）： 轮询（默认）:按照请求时间分发到不同服务器，如果有服务器宕机的话会自动剔除。 weight：当服务器之间存在性能差异的时候，可以使用指定优先访问性能好的服务器。 ip_hash：在upstream中采用ip_hash指令,如果客户已经访问了某个服务器，当用户再次访问时，会将该请求通过哈希算法，自动定位到该服务器。每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。此种策略，可以实现同一个用户访问同一台服务器，会话不会丢失，但是可能会分配不均 准备好几个新服务器（虚拟机），最少三个，确保里面的参数配置相同（装好Nginx+PHP），主要是编辑 nginx.conf 文件，这个文件在你安装nginx目录的conf文件夹里面。例如： &#x2F;www&#x2F;server&#x2F;nginx&#x2F;conf 先配置分发用的nginx（地铁工作人员），按照以下添加配置： 到这里分发的Nginx服务器已经配置好，输入以下命令检查配置是否有问题： 出现以下的就是配置没问题，有问题就根据报错进行排查： 确认无误之后，记得要重启或者重载Nginx配置。 然后现在继续配置访问的服务器A和B（地铁出口A和B），按照以下进行配置： 配置完之后像分发服务器一样检查和重启。 然后在分发服务器，访问服务器A和B的根目录里面建立一个index.html 里面分别写一个 demo，demo1，demo2 最后访问分发服务器里面写的分发入口ip或者域名。 到这里就负载均衡就完成了，报错的话自己多排查一下吧，我也不写weight和ip_ hash的demo了，都差不多，百度一下就出来了。 "},{"title":"PHP获取微信小程序session_key和openID","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/PHP/PHP%E8%8E%B7%E5%8F%96%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8Fsession_key%E5%92%8CopenID/","tags":[["PHP","/tags/PHP/"]],"categories":[["PHP","/categories/PHP/"]],"content":"PHP获取微信小程序session_key和openID引言 由于微信改版，本来是由前端获取这个session_key和openID的，现在由后端进行获取。 步骤 获取条件，前端获取code，然后发送给后端，自己拿好AppID和AppSecret。 上码： "},{"title":"PHP计算小数点精度丢失-BcMath","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/PHP/PHP%E8%AE%A1%E7%AE%97%E5%B0%8F%E6%95%B0%E7%82%B9%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1-BcMath/","tags":[["PHP","/tags/PHP/"]],"categories":[["PHP","/categories/PHP/"]],"content":"PHP计算小数点精度丢失-BcMath引言 PHP计算小数点精度丢失，计算金额的时候特别要注意这些细节，不然你知道的。 步骤 在有些时候要进行小数点计算后判断会遇到下面类似的问题： 输出的是false和57。Javascript, python等。也会出现同样的问题。 官网的解释: 官网给出的解决方案-BcMath(任意精度数学函数)： 参照官网给出方案得出以下正确写法： "},{"title":"PHP验证苹果支付Apple数据","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/PHP/PHP%E9%AA%8C%E8%AF%81%E8%8B%B9%E6%9E%9C%E6%94%AF%E4%BB%98Apple%E6%95%B0%E6%8D%AE/","tags":[["PHP","/tags/PHP/"]],"categories":[["PHP","/categories/PHP/"]],"content":"PHP验证苹果支付Apple数据步骤 苹果webapp的支付大致的思路，（这里我简写了因为苹果的商品需要到苹果认证拿到一个认证的商品id，挺麻烦的因为是虚拟商品）前端组装好参数先向苹果端下单支付，获取到苹果返回的加密数据，然后PHP拿到这个加密数据进行组装，再次向苹果发送数据，由苹果自己解密认证，认证成功了这个支付才算完成。 验证apple函数： 使用方法： "},{"title":"ThinkPHP5.0以上的自定义验证规则添加","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/PHP/ThinkPHP5.0%E4%BB%A5%E4%B8%8A%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E9%AA%8C%E8%AF%81%E8%A7%84%E5%88%99%E6%B7%BB%E5%8A%A0/","tags":[["PHP","/tags/PHP/"],["ThinkPHP","/tags/ThinkPHP/"]],"categories":[["PHP","/categories/PHP/"]],"content":"ThinkPHP5.0以上的自定义验证规则添加步骤 在使用表单验证的时候，会有概率遇到重复验证一些特殊的字段。 比如手机号，身份证号，在平时表单验证的时候会通常这么做。如下： 但是比如我在填写注册信息的时候要验证手机号字段，短信接口验证手机号字段等多个场景时候，就要复制多几份出来，也许有人会说tp的表单验证有验证场景的使用 官方文档: 我个人认为，在字段少的情况确实可以使用，但是字段多的情况下，会显的比较混乱。比如个人信息表单和收货地址表单都会用到手机号。总不能一股脑全写在一起然后使用验证场景吧。当然这是个人习惯和认为。 除了以上的方式，还有一个便捷的办法，在Validate.php添加自定义的规则。 Validate.php在tp项目根目录的框架系统目录&#x2F;框架核心类库目录下，例如： 找到protected $regex 这个属性： 修改以下： 在表单验证的时候只要填写你自定义的名称就可以用了，如下： "},{"title":"php中简单的使用redis发布与订阅","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/PHP/php%E4%B8%AD%E7%AE%80%E5%8D%95%E7%9A%84%E4%BD%BF%E7%94%A8redis%E5%8F%91%E5%B8%83%E4%B8%8E%E8%AE%A2%E9%98%85/","tags":[["PHP","/tags/PHP/"],["redis","/tags/redis/"]],"categories":[["PHP","/categories/PHP/"]],"content":"php中简单的使用redis发布与订阅引言 Redis发布和订阅的介绍（摘抄）： 基于事件的系统中，Pub&#x2F;Sub是目前广泛使用的通信模型，它采用事件作为基本的通信机制，提供大规模系统所要求的松散耦合的交互模式：订阅者(如客户端)以事件订阅的方式表达出它有兴趣接收的一个事件或一类事件；发布者(如服务器)可将订阅者感兴趣的事件随时通知相关订阅者。 消息发布者，即publish客户端，无需独占链接，你可以在publish消息的同时，使用同一个redis-client链接进行其他操作（例如：INCR等） 消息订阅者，即subscribe客户端，需要独占链接，即进行subscribe期间，redis-client无法穿插其他操作，此时client以阻塞的方式等待“publish端”的消息；这一点很好理解，因此subscribe端需要使用单独的链接，甚至需要在额外的线程中使用。 步骤 Redis的发布和订阅应用场景：消息通知，比如下单之后的订单提示等。。 自行安装好redis，我这里就不介绍安装了。准备好以下PHP文件，并以PHP-cli的方式运行。 发布文件 - send.php : 发布文件1 – send1.php (和send.php一样的就是改了点发送内容)： 订阅文件 - receive.php: 用PHP-cli的方式运行，根据标号依次执行： Redis的发布和订阅简单使用就到这里了，要想把订阅推送到前端展示的话，就要使用websocket进行交互，我这里就不写了。 "},{"title":"redis队列秒杀原理","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/PHP/redis%E9%98%9F%E5%88%97%E7%A7%92%E6%9D%80%E5%8E%9F%E7%90%86/","tags":[["PHP","/tags/PHP/"],["redis","/tags/redis/"]],"categories":[["PHP","/categories/PHP/"]],"content":"redis队列秒杀原理引言 在商品秒杀等场景中，使用普通的方法处理的话，容易出现以下问题： - 高并发下的流量冲击数据库 - 商品容易出现库存超卖问题 秒杀的大致逻辑：秒杀前，商品上架的时候，将库存添加到redis的队列中，秒杀开始的时候查询这个商品的redis的队列（队列先进先出原则），从这个队列取出值，取出成功的下单，取出失败的全部返回false。 步骤 准备好redis的环境，复现秒杀场景，开干，先建一个测试用的数据库和数据表： 这里是我写的一个秒杀的demo，在项目的根目录下创建一个叫redis.php 的文件，把以下代码复制进去： RushBuy这个类里面写了很多注释，跟着注释走这个逻辑，主要功能的话是商品加入队列和模拟用户秒杀，下面是把商品加入队列的操作，在项目的根目录创建一个goodsadd.php，复制以下代码: 在项目的根目录创建一个秒杀用的入口orderadd.php，复制以下代码： 环境和内容都准备好了，下面进行用户的模拟秒杀测试，其实本质上就是进行压力测试，先访问goodsadd.php，进行商品的库存加入队列（这里会得到10个长度，库存数据默认给了10），然后开始准备压力测试模拟用户秒杀。 压力测试的话，我这里使用的是apache自带的ab测试（因为方便），在Apache的bin目录下执行以下类似的命令： 最终得到测试结果: 数据库的记录结果： 从数据库结果来看500人抢购10个库存（在数据表结构上有默认添加一条数据）也没有出现商品的库存超卖问题，里面没有满500个的原因，有个别请求失败了。 到这里模拟用户秒杀的简单场景就结束了，这里只是一个简单的demo，没有考虑复杂场景，仅供参考，有兴趣的话，可以了解一下缓存雪崩，缓存穿透，缓存击穿等问题。 "},{"title":"swoole简单的推送demo","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/PHP/swoole%E7%AE%80%E5%8D%95%E7%9A%84%E6%8E%A8%E9%80%81demo/","tags":[["PHP","/tags/PHP/"],["swoole","/tags/swoole/"]],"categories":[["PHP","/categories/PHP/"]],"content":"swoole简单的推送demo引言 早期写过swoole的消息推送，由于偷懒，没有把代码留下，就剩下几个照片，存着将就参考参考。 步骤 准备好laravel+swoole 用的都是最新的版本，这里就不说详细的安装教程了。觉得安装麻烦的话用宝塔安装也行， swoole官网教程。 自行安装好redis，我这里就不介绍安装了。准备好以下PHP文件，并以PHP-cli的方式运行。 使用laravel的artisan创建命令 : 编辑app&#x2F;Console&#x2F;Kernel.php这个文件 注意哦 是console这个文件夹的： 编辑app&#x2F;Console&#x2F;Commands&#x2F;Swoole.php文件: 前端html代码，自己创建一个view视图 然后定义好路由。这里就不多说了： 这里就准备好了，服务端和客户端，就差一个推送端，这个推送端就随便找个控制器调用就好了。我是放在自定义函数里面，一般来说是不建议放在自定函数里面。 做完以上步骤就可以跑demo试试。 命令行进入项目的根目录执行以下命令。一定要先执行这句，再测试。目的是开启server端: 看看有没有报错，有报错就进行一些修正。没有报错就进行连接和推送测试。var_dump和echo会输出数据。注意事项：不可以使用 exit die 等终止执行的命令。 然后客户端html先进行websocket连接 发送用户id进行绑定。 访问推送端 推送数据到指定id。 这里实现的是简单的推送demo，具体功能还是要根据实际来。 "},{"title":"svn小乌龟客户端的安装","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/%E6%9D%82%E9%A1%B9/svn%E5%B0%8F%E4%B9%8C%E9%BE%9F%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E5%AE%89%E8%A3%85/","tags":[["svn","/tags/svn/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"svn小乌龟客户端的安装引言 因为特殊需要采用svn做代码版本控制。 步骤 下个客户端，先安装好，虽然没这么快用上：官方下载 这个是svn的包。 这个是svn的语言包-中文版，觉得自己英文牛逼的可以不用。 安装简单，就是点点点好了，就不写出来了，安装详细教程 安装完之后，右键设置，全英文？莫慌，看图片对比一下，有个钳子的形状，就是设置了。 打开设置。 svn的客户端就安装完了。 "},{"title":"使用svn小乌龟上传代码并部署上线项目","date":"2023-11-28T16:00:00.000Z","url":"/2023/11/29/%E6%9D%82%E9%A1%B9/%E4%BD%BF%E7%94%A8svn%E5%B0%8F%E4%B9%8C%E9%BE%9F%E4%B8%8A%E4%BC%A0%E4%BB%A3%E7%A0%81%E5%B9%B6%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%E9%A1%B9%E7%9B%AE/","tags":[["svn","/tags/svn/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"使用svn小乌龟上传代码并部署上线项目引言 该文章配置svn上传代码后自动部署到线上目录。 步骤 配置服务端版本库更新至web目录，执行以下命令： 使用钩子进行SVN自动更新到线上项目目录，执行命令： 将post-commit.tmpl文件复制出来叫做post-commit，svn将要执行的是post-commit文件，执行以下命令： 编辑post-commit文件，执行命令： 参考图，紫色框是需要注释掉的，红色框是需要添加的： 设置post-commit文件权限，执行以下命令： 将SVN设置开机自启动，先查找svn命令地址： 新建开机自启： 脚本内容： 脚本内容说明： #! &#x2F;bin&#x2F;bash 脚本头部 &#x2F;usr&#x2F;bin&#x2F;svnserver svn命令地址 &#x2F;www&#x2F;wwwroot&#x2F;svn&#x2F;svnrepos 这个是你项目的版本库目录 到这里配置就结束了。可以测试一下svn检出到本地,然后新建一些文件或内容，提交到svn的版本库。提交成功后可以去看看，新建的文件之类的东西有没有同步到你的线上项目文件夹。 补充。 在华为云centos8.2版本的svn提交，钩子执行失败，原因是钩子设置的语言编码是 zh_CN.UTF-8，但是系统是不支持这个编码，所以需要手动查询系统的编码，查询系统编码的命令是：locale ,执行之后会有 LANG&#x3D;en_US.UTF-8 这样的一句类似的话，把这句话复制下来然后重新编辑 post-commit文件， export LANG&#x3D;en_US.UTF-8 覆盖 export LANG&#x3D;zh_CN.UTF-8这句话，就可以了，如果服务器上的svn版本被锁定了就执行 svn cleanup 这句话。 如图： "},{"title":"liunx安装svn小乌龟服务端","date":"2023-11-23T16:00:00.000Z","url":"/2023/11/24/Centos/liunx%E5%AE%89%E8%A3%85svn%E5%B0%8F%E4%B9%8C%E9%BE%9F%E6%9C%8D%E5%8A%A1%E7%AB%AF/","tags":[["Centos","/tags/Centos/"],["svn","/tags/svn/"]],"categories":[["Centos","/categories/Centos/"]],"content":"liunx安装svn小乌龟服务端步骤 通过yum命令安装svnserve，命令如下： 创建版本库目录（存放版本库的）： 创建svn版本库： 进入你刚创建的版本库 cd &#x2F;www&#x2F;svn&#x2F;svnrepos&#x2F;xxxx 输入 ll 命令可以看见以下文件： 进入conf文件夹： authz：负责账号权限的管理，控制账号是否读写权限 passwd：负责账号和密码的用户名单管理 svnserve.conf：svn服务器配置文件 编辑authz，按照图片上面进行添加： [&#x2F;] 所有版本库 默认开启 可以指定账号访问指定的库 svn1 svn2 这两个是账号 自己定义 rw 读写权限 r读权限 自己看需求来 编辑passwd文件： svn1&#x3D;123456 &#x3D;》 账号&#x3D;密码 编辑svnserve.conf： 找到红框的四句话 去掉# 保存。 开放端口3690。执行以下命令，执行完后记得去服务器的安全组开放该端口： 到这里svn的服务端暂时配置完了。 启动svn服务： 这里可以开始测试把svn仓库检出到本地。 新建一个文件夹，然后右键svn检出： 版本库url填写格式 ： svn&#x2F;&#x2F;你的ip：端口号&#x2F;版本库名称 然后链接成功会弹出窗口让你填写账号和密码。 "},{"title":"mysql+navicat-导出数据库文档","date":"2023-11-23T16:00:00.000Z","url":"/2023/11/24/MYSQL/mysql+navicat-%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E6%A1%A3/","tags":[["mysql","/tags/mysql/"],["navicat","/tags/navicat/"]],"categories":[["MYSQL","/categories/MYSQL/"]],"content":"mysql+navicat-导出数据库文档引言 现在有些同事（不是我，我喜欢先写文档再建表），喜欢直接在数据库建表，然后不写数据库文档，事后没办法快捷写数据库文档，很苦恼，但之前有个同事写的文档挺快的，所以我问了问秘诀，用sql语句生成就可以了，然后顺带查了查资料，确实是个好方法。 步骤 先准备一下Navicat，再创建一个测试库，再创建以下数据表： 下面是参数的介绍： table_catalog 不管是table&#x2F;view 这个列的值总是def table_schema 表&#x2F;视图所在的数据库名 table_name 表名&#x2F;视图名 column_name 列名 column_default 列的默认值 is_nullable 是否可以取空值 data_type 列的数据类型 character_maximum_length 列的最大长度（这列只有在数据类型为char column_type 列名列类型这个类型比data_type列所指定的更加详细，如data_type 是int 而column_type 就有可以能是int(11) column_key 列上的索引类型 主键–&gt;PRI column_comment 字段注释 在Navicat里面进行以下查询(单表查询)： 查询得出以下结果： 开始导出结果，按照以下操作步骤指示（不想导出就复制粘贴就好）： 得到导出结果： 有点难看，手动修饰一下： 以上就是单表查询导出结果了，下面的是多表导出（全库），一个个表导出有点累： 查询结果： 可按照上面的导出步骤（我很懒），得到以下导出结果: 修饰一下： 导出数据库文档这样就完成了。 "},{"title":"mysql精确匹配-find_in_set","date":"2023-11-23T16:00:00.000Z","url":"/2023/11/24/MYSQL/mysql%E7%B2%BE%E7%A1%AE%E5%8C%B9%E9%85%8D-find_in_set/","tags":[["mysql","/tags/mysql/"]],"categories":[["MYSQL","/categories/MYSQL/"]],"content":"mysql精确匹配-find_in_set引言 有时我们在做数据库查询时，需要得到某字段中包含某个值的记录，但是它也不是用like能解决的，使用like可能查到我们不想要的记录，它比like更精准，这时候就要用到mysql的FIND_IN_SET函数了。 步骤 例如，创建cc表，list字段，需要查询出list包含11的数据： 没有用过find_in_set的同志们，一般来说会想到用like来模糊查询这样的数据，例如： 这样查询虽然可以查到11的数据，但也会查询到不要的数据。： 使用find_in_set查询,可以精确的查询到包含11的数据： find_in_set的使用方法： find_in_set(‘你要查询的字符串’,’你的字段名称’) 注意事项： 使用find_in_set会全表扫描。 查询的字段数据用英文逗号拼接的。 在数据量多的情况下不合适使用，会全表扫描，不会使用索引。 "},{"title":"集群-搭建MYSQL主从数据库","date":"2023-11-23T16:00:00.000Z","url":"/2023/11/24/MYSQL/%E9%9B%86%E7%BE%A4-%E6%90%AD%E5%BB%BA%E4%B8%BB%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%BA%93/","tags":[["mysql","/tags/mysql/"]],"categories":[["MYSQL","/categories/MYSQL/"]],"content":"集群-搭建MYSQL主从数据库引言 搭建主从数据库的目的就是减少数据库的压力，遇到大流量的时候不会死这么快。 步骤 先准备好两个虚拟机(centos7.8)，里面已经搭好了LNMP(nginx1.8，mysql5.7，php7.4)的环境，（我用的宝塔，挺方便的，不一定要使用宝塔的环境，自行安装也可以的，记得安装的位置就好）。 配置主数据库： 配置从数据库： 检查配置项, 主从数据库分别检查，出现以上的配置参数就是没问题了： 查看binlog的开启情况： 主数据库新建从数据库访问账号,并给予相关的权限： 数据库是克隆出来的请注意（不是克隆的请忽略），在从数据库安装目录下的data文件夹，里面有个auto.cnf文件，删掉，然后重启数据库，因为是克隆出来的，里面的uuid和主数据库是一样的，会导致Slave_IO_Running配置变ON。 查看主数据的binlog的文件位置和端口号： 新环境的朋友可以跳到配置从数据库的位置，已有数据库运行中的，请认真看，配置主从之前旧的数据是不会自动同步到从数据库里面的，所以需要自己备份数据到从数据库，再进行主从配置。 主数据库的数据备份，备份前先给个只读锁，顾名思义，只允许读操作。建议：找个夜神人静的时候进行操作，避免外部访问产生新数据： 备份主数据库： mysqldump 是 MySQL 自带的逻辑备份工具 -A 备份全部数据库 -F 刷新二进制日志 –master-data&#x3D;2 追加二进制位置和文件输出到sql中 gzip 将mysqldump的数据压缩,节省存储空间 命令 &gt; 文件 文件作为命令输出 &#x2F;root&#x2F;cc.sql.gz 保存路径+备份名称 把数据导入从数据库： gunzip命令用于解压文件 命令 &lt; 文件 文件作为命令输入 &#x2F;root&#x2F;cc.sql.gz 文件路径+主数据库的备份文件 配置从数据库： 配置完后退出数据库，去数据库安装目录data下查看: 进入从数据库： 新环境的朋友直接跳过，已有数据库运行中的一定要做这一步）进入主数据库，关闭只读锁，恢复可写状态: 到这里就配置完了，然后可以在主数据库添加数据，去从数据库查看是否有同步。 数据库集群有三种方式和优点（目前做的测试是一主一从，一主多从也是一样的操作）： 一主一从：mysql读写分离,使数据库压力分散,提高服务器性能。 一主多从：当主服务器出问题后,可以选择一台从服务器变更为主服务器,继续提供服务。 多主多从：一台主服务器出问题了,可立即切换另一台主服务器提供服务。 从以上的优点得出待思考的问题： 主从同步数据延迟问题。 一主多从虽然可以提高可用性,但在主服务器宕机的时候,可能会出现一些数据同步未完成,数据丢失的问题,需要在主服务器恢复后增量恢复。 多主多从需要考虑主服务器都在使用时,id自增,主键冲突的问题,以及其中一台主服务器宕机时间至恢复时间内的数据丢失,增量同步的问题。 "},{"title":"centos安装jenkins","date":"2023-11-22T16:00:00.000Z","url":"/2023/11/23/%E6%9D%82%E9%A1%B9/centos%E5%AE%89%E8%A3%85jenkins/","tags":[["jenkins","/tags/jenkins/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"centos安装jenkins引言 早期使用walle进行代码发布，但是参考资料比较少，后改用jenkins。 步骤 安装Java: 导入Jenkins存储库的GPG密钥：使用以下命令导入Jenkins存储库的GPG密钥： 添加Jenkins存储库：创建一个名为jenkins.repo的文件，并将以下内容添加到文件中： 在文件中添加以下内容： 安装Jenkins：使用以下命令安装Jenkins： 安装的过程中，有概率会遇见 Error: GPG check FAILED 问题： 启动jenkins： 设置Jenkins自动启动： 查看Jenkins日志： 查看Jenkins服务的状态： 检查8080端口是否占用： 注意：要开放8080端口，访问jenkins的页面是IP:端口，例子： 哪天不想用jenkins了（这是后话咯）： 进入web页面的时候会显示下面的样子： 查询默认的密码： 复制默认密码粘贴上去就好了，后续的安装步骤比较简单，就不写了，点点点就完了。 配置NGINX绑定jenkins： 修改jenkins端口（记得端口开放）： "},{"title":"Laravel的with动态条件用法","date":"2023-11-14T16:00:00.000Z","url":"/2023/11/15/PHP/Laravel%E7%9A%84with%E5%8A%A8%E6%80%81%E6%9D%A1%E4%BB%B6%E7%94%A8%E6%B3%95/","tags":[["PHP","/tags/PHP/"],["Laravel","/tags/Laravel/"]],"categories":[["PHP","/categories/PHP/"]],"content":"Laravel的with动态条件用法引言 在laravel模型中，已知with方法可以预加载模型中定义的关联方法，一般来说关联好模型就直接with（模型方法名称）查询就好，但是我想关联的时候筛选一部分数据的时候就要写一个条件查询。官方文档： #为预加载添加约束。 步骤 举一个例子，已知以下两个表，设查询商品列表，筛选出价格区间的商品： 商品表 goods 商品id goods_id 商品名称 goods_name 价格表 prices 价格id price_id 商品id goods_id 价格 price Goods模型： Index控制器: "},{"title":"Laravel队列与supervisor简单使用","date":"2023-11-14T16:00:00.000Z","url":"/2023/11/15/PHP/Laravel%E9%98%9F%E5%88%97%E4%B8%8Esupervisor%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","tags":[["PHP","/tags/PHP/"],["Laravel","/tags/Laravel/"],["supervisor","/tags/supervisor/"]],"categories":[["PHP","/categories/PHP/"]],"content":"Laravel队列与supervisor简单使用引言 之前写过一篇Laravel队列简单教程，这是后续搭配supervisor一起使用。 步骤 Supervisor的作用：监控进程状态，异常退出时能自动重启。 安装Supervisor： Supervisor主配置文件: Supervisor子配置文件(supervisord.d目录下的所有.ini结尾的文件)： supervisor.conf主配置文件说明： *.ini子进程配置文件说明: 了解以上配置之后，在supervisord.d目录下面新增一个queue.ini的子配置文件： 启动守护进程Supervisor： 查看Supervisor状态： 出现以下结果： 可以看到已经启动了进程25278是队列的执行命令，访问cc方法（简单队列案例文章有说明），可以发现队列运行成功并把数据添加到数据库里面。 然后开始进行Supervisor终止测试，查询PHP的进程： 出现以下： 和Supervisor状态是一样的进程号，进行kill操作： 再次进行PHP进程查询和Supervisor状态查询： 进程号变化，命令依旧执行，队列的守护进程完成。 设置开启自启： Supervisor命令（启动&#x2F;停止&#x2F;重启）以下： "},{"title":"laravel使用简单队列案例","date":"2023-11-14T16:00:00.000Z","url":"/2023/11/15/PHP/laravel%E4%BD%BF%E7%94%A8%E7%AE%80%E5%8D%95%E9%98%9F%E5%88%97%E6%A1%88%E4%BE%8B/","tags":[["PHP","/tags/PHP/"],["Laravel","/tags/Laravel/"],["queue","/tags/queue/"]],"categories":[["PHP","/categories/PHP/"]],"content":"laravel使用简单队列(queue)案例引言 队列是一种特殊的线性表，只能在表头进行删除操作，表尾进行添加操作，简单来说就是数据的先进先出原则。 另类的理解案例：你（消费者）在公司上班，按照领导（生产者）给你的任务表（队列）开始搬砖干活，任务表里面有着任务1，任务2，任务3，干活嘛只能一件一件干，所以要完成任务1才能去做任务2，以此类推，直到干完活，想屁吃呢，领导只会给你不停的生产任务，比如刚刚生产出来任务4嘛，就会安排在任务3后面，以此类推，然后你就不停的干活，日复一日，年复一年。Ps：队列本质上就是一堆任务排队，先进先出。 队列的应用场景：群发短信，订单系统有大量的日志，秒杀设计等，大致上就是数据量多，一下处理不完的，就会使用队列处理。 步骤 准备好laravel6.0框架，另外这个是在windows的情况下写的，没有使用守护进程那些。 我要实现的内容，就是访问一个页面产生一个访问记录添加到队列里面，然后队列自动把这个记录写进数据库。 配置laravel的.env文件: 做数据迁移，注意要保证好数据库能连接： 创建一个记录表，用来存储访问的记录： 最终数据库长这个样: 生成一个队列的类： 执行完后，到app的目录下会有一个Jobs的目录，所有默认的队列类都会在这里，打开Logs.php，复制以下的内容，记得要看里面的注释： 创建一个控制器： 在app\\Http\\Controllers的目录下会有一个LccController控制器，打开编辑： 编辑路由文件，routes&#x2F;web.php,添加以下代码: 这样就可以进行访问了，你可以多访问几次，访问多了你就去数据表jobs看看是不是多了一些数据，这些数据就是队列里面的任务。 没有执行队列里面的任务，是因为队列没有开启，执行下面的命令（注意：队列的执行是常驻的，需要守护进程之类的辅助监听状态）： 执行完命令之后，队列自动执行任务： 从上得出，任务执行完之后会自动删除，并且数据是有序执行的。 进数据库里面还有一个表failed_jobs，用来存储执行失败任务，做一个执行失败测试： 把之前的Logs队列类里面的方法复制到ErrLogs队列类里面，并修改以下方法： 在LccController控制器添加多一个err的方法并引入jobs下的ErrLogs队列类： 添加一个路由： 访问这个err的路由多几次，然后去看看failed_jobs表有没有添加数据，没有的话就检查队列是否开启，我是一直开启的，所以每次生产就会直接被消费掉了。 failed_jobs会有以下的内容： Exception：这个是执行错误原因。Payload：这个是说明哪个队列类。 有些场景队列错误了想要立刻发邮件提示技术人员的话，laravel是有提供一个failed函数，ErrLogs的队列类上添加以下方法： 添加一个报告用的表： 接着访问这个err的路由多几次（一定要先重启队列，任何队列类修改之后一定要重启），然后去看看failed_jobs表和test表有没有添加数据。 之前错误了这么多队列任务，不能放着吧，把错误原因修正，添加errlogs表： 错误修正了，那就把之前错误的队列任务找回来，重新执行： 你就发现之前的failed_jobs表里面的数据会还原到jobs表里面，同时errlogs的表也进行添加了数据，如果队列还开着的话就会自动重新执行，没有开的话就执行: Laravel简单的队列（jobs）就是这么使用的，真实使用还需要配合守护进程（Supervisor）等。 "},{"title":"Centos7.6下的LAMP之Apache编译","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Centos/Centos7.6%E4%B8%8B%E7%9A%84LAMP%E4%B9%8BApache%E7%BC%96%E8%AF%91/","tags":[["Centos","/tags/Centos/"]],"categories":[["Centos","/categories/Centos/"]],"content":"Centos7.6下的LAMP之Apache编译引言 平时都是使用集成环境开发，增加开发效率，一时心血来潮决定自己手动编译一次。虽然以前已也编译过，但是每个版本终究还是不同的，有坑需要踩的。 准备centos7.6环境。注意：该文章只使用于借鉴，没有使用于生产环境。慎重。 步骤 检查是否安装过 wget： 安装wget： 进入源码包的存放位置，没有就创建一个，例如： 准备好Apache的源码包分别执行： 安装LAMP的依赖包，执行命令： 开始编译安装Apache，apache版本-&gt;httpd-2.4.43 依赖包版本-&gt; pcre-8.42 apr-1.7.0 apr-util-1.6.1。 源码安装 apr-1.7.0.tar.gz： 源码安装 apr-util-1.6.1.tar.gz: 源码安装pcre-8.42.tar.gz: 源码安装httpd-2.4.43.tar.gz： 到这里Apache就安装完了，现在开始配置Apache： 编辑httpd.conf文件（Apache配置文件）操作点： （Apache配置文件）修改点： #ServerName www.example.com:80 修改成 ServerName localhost:80 注意要去掉注释# DocumentRoot “&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs” 修改成 DocumentRoot “&#x2F;www” 注意：www是小写 &lt;Directory “&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs”&gt; 修改成 &lt;Directory “&#x2F;www”&gt; 注意：www是小写 DirectoryIndex index.html 修改成 DirectoryIndex index.php index.html #Include conf&#x2F;extra&#x2F;httpd-vhosts.conf 修改成 Include conf&#x2F;extra&#x2F;httpd-vhosts.conf 编辑完httpd.conf文件，接着编辑httpd-vhosts.conf文件（虚拟主机配置）执行以下操作： 编辑httpd-vhosts.conf: 删除以下的配置: 新增配置: 到这里Apache总体配置完了。 以下是Apache的启动，停止，重启的命令： 总结 编译过程中遇到问题莫慌，百度一下其实有很多例子和解决方案，虽然有很多标题党和广告但是自己也要能分辨出有效信息。 为了保证文章的是否有错误的语句，写完之后，按照自己的写文章再搭建了一次，确保没有问题的出现。 "},{"title":"Centos7.6下的LAMP之Mysql编译","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Centos/Centos7.6%E4%B8%8B%E7%9A%84LAMP%E4%B9%8BMysql%E7%BC%96%E8%AF%91/","tags":[["Centos","/tags/Centos/"]],"categories":[["Centos","/categories/Centos/"]],"content":"Centos7.6下的LAMP之Mysql编译引言 安装mysql8.0需要高版本的cmake和gcc，所以要手动更新这两个依赖，这两个更新的方法，我另外写了两篇文章。更新完才能执行以下的操作。注意事项：系统盘最好要大于60G。不然会安装失败。 步骤 进行安装前做些准备工作，比如源码包，依赖包，以及冲突环境，例如以下： 如果存在就要卸载了，不存在就忽略吧，原因是安装mysql的话会和mariadb的文件冲突，执行以下命令： 安装依赖，执行以下操作： 下载源码包，执行以下操作： 创建mysql用户，执行以下操作： 创建安装目录和数据目录，执行以下操作： 开始解压编译，执行以下操作： 编译安装会出现一些问题，就是一些函数不存在要求替换，问题可以参考这个文章，Centos7.6下的Mysql8.0.20编译错误合集，有些问题可以仔细看看，手动替换上面的函数，然后重新make &amp;&amp; make install 就好。 初始化mysql： 初始化完之后要记得保存mysql的临时密码。 安装ssl： 启动mysql （临时操作，需要另外开一个窗口执行）: 连接mysql： 连接成功，修改密码（我这里修改root只是为了方便，正式环境不要使用简单的密码）: 设置远程登录，为了方便mysql的管理工具连接: 设置环境变量: 设置开机自动启动: 添加以下语句: 设置开机自启: 注意 生产环境中千万不要把所有权限都分配给远程登陆用户。 Navicat工具版本在12或以下的，会连接不上，原因是mysql8.0版本的加密方式有变更，或出现Authentication plugin ‘caching_sha2_password’这样的问题，需要更改密码的加密方式，这里需要另外自行找答案了，我这里就不详细描述了。 在正式环境下请打开3306端口，由于我这里是直接关闭防火窗的Sao操作。 到这里mysql的安装结束了，这里太繁琐了，电脑不好完全跑不动，网速不好的情况下建议那些大的包从迅雷去下载然后传到虚拟机会快很多。 mysql命令 systemctl start mysql 启动mysql服务 systemctl restart mysql 重启mysql服务 systemctl status mysql 查询mysql状态 "},{"title":"Centos7.6下的LAMP之PHP编译","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Centos/Centos7.6%E4%B8%8B%E7%9A%84LAMP%E4%B9%8BPHP%E7%BC%96%E8%AF%91/","tags":[["Centos","/tags/Centos/"]],"categories":[["Centos","/categories/Centos/"]],"content":"Centos7.6下的LAMP之PHP编译步骤 安装以下的依赖： 如果要使用mbstring的功能一定要安装oniguruma，不安装oniguruma就会报No package ‘oniguruma’ found。 选用PHP 7.4.8 作为编译版本： 预编译： 编译&amp;&amp;安装： 安装完之后开始配置PHP，拷贝php配置文件(基于&#x2F;usr&#x2F;local&#x2F;src&#x2F;php-7.4.8路径)： 编辑配置文件： php-fpm.conf文件去掉前面的 ; 号： 编辑 www.conf： www.conf文件去掉前面的 ; 号： 编辑开机自启文件： php-fpm.service添加下列语句： 在命令行中运行以下命令，生成静态文件并部署到 GitHub Pages： 添加php到系统环境变量： 配置Apache解析php文件： httpd.conf修改： 到这里就配置完了，重启Apache和PHP： 注意 PHP命令： systemctl enable php-fpm.service 开机自启 systemctl disable php-fpm.service 取消开机自启 systemctl reload php-fpm.service 重新加载服务 systemctl status php-fpm.service 查看状态 systemctl start php-fpm.service 启动php服务 systemctl stop php-fpm.service 停止php服务 systemctl restart php-fpm.service 重启php服务 "},{"title":"Centos7.6下的Mysql8.0.20编译错误合集","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Centos/Centos7.6%E4%B8%8B%E7%9A%84Mysql8.0.20%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF%E5%90%88%E9%9B%86/","tags":[["Centos","/tags/Centos/"]],"categories":[["Centos","/categories/Centos/"]],"content":"Centos7.6下的Mysql8.0.20编译错误合集引言 搭建mysql8.0.20遇见的问题点汇总。 步骤 错误：‘SYS_gettid’： 解决方案： 错误：‘os_compare_and_swap_thread_id’ 注意：文件名是lock0lock.cc: 解决方案： 错误：‘os_compare_and_swap_thread_id’注意：文件名是trx0trx.cc： 解决方案： "},{"title":"Centos7.6升级cmake","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Centos/Centos7.6%E5%8D%87%E7%BA%A7cmake/","tags":[["Centos","/tags/Centos/"]],"categories":[["Centos","/categories/Centos/"]],"content":"Centos7.6升级cmake引言 由于要手动编译mysql8，需要高版本的cmake，不得不更新cmake。 步骤 进入src目录，执行以下命令： 下载源码包： 解压源码包： 进入解压后的文件夹： 开始配置(–prefix 指定安装目录)： 配置完就开始编译安装： 如果是系统有自带的cmake，就要删除，已删除过的请忽略： 安装完创建命令的软连接： 执行版本的命令： 出现如下就是成功了： "},{"title":"Centos7.6升级gcc","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Centos/Centos7.6%E5%8D%87%E7%BA%A7gcc/","tags":[["Centos","/tags/Centos/"]],"categories":[["Centos","/categories/Centos/"]],"content":"Centos7.6升级gcc引言 mysql8需要，升级gcc。 步骤 安装依赖： 进入源码目录： 下载源码包： 解压文件： 进入解压的文件夹： 继续安装依赖： 执行命令后它会自动下载mpfr、gmp、mpc isl这4个库。 建立一个文件夹： 进入文件夹： 配置： 编译和安装： 删除旧版本的gcc： 创建软连接： 查看版本： 就这样完成了？不，你错了，还有一个叫动态库的东西，版本更新了，但是动态库不一定更新了。是不是很惊喜（我更新完就去编译mysql了，然后炸了，丢）。 这里就不做是否动态库更新的判断了，直接就当做动态库没有更新。 查询gcc的安装路径: 进入操作目录: 复制安装好的gcc文件到操作目录: 删除旧的软连接，怕删错就拷贝一份做备份: 添加软连接: 到这一步才是安装完成。 "},{"title":"Centos7.6安装oniguruma","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Centos/Centos7.6%E5%AE%89%E8%A3%85oniguruma/","tags":[["Centos","/tags/Centos/"]],"categories":[["Centos","/categories/Centos/"]],"content":"Centos7.6安装oniguruma引言 为啥要安装oniguruma，是因为PHP7.4.x中mbstring的正则表达式功能需要oniguruma。 步骤 执行以下代码： 根据小网站的提示，configure必须要有“–libdir&#x3D;&#x2F;lib64”这个参数，不然编译php7.4.x的时候一定会报No package ‘oniguruma’ found。当然除非你编译PHP的时候不使用mbstring的功能。 注意 找挺久的一个资料，虽然广大网友也遇到了这个问题，但是终究没有试出一个合适的方案，翻了很久终于在一个小网站里面找到了。"},{"title":"centos7.6的ip查询和网卡配置","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Centos/centos7.6%E7%9A%84ip%E6%9F%A5%E8%AF%A2%E5%92%8C%E7%BD%91%E5%8D%A1%E9%85%8D%E7%BD%AE/","tags":[["Centos","/tags/Centos/"]],"categories":[["Centos","/categories/Centos/"]],"content":"centos7.6的ip查询和网卡配置步骤 在centos7中，查看ip的命令 ip addr 。 在ip addr 命令中 可以看到网卡没有激活，所以没有显示ip 。 使用命令vi &#x2F;etc&#x2F;sysconf ig&#x2F;network-scripts&#x2F;ifcfg&#x2F;ens33 编辑网卡配置。 编辑网卡会出现以下内容，红框框住的是需要编辑 的配置，ONBOOT是指明在系统启动时是否激活网卡,将no改成yes。 改成以下，:wq 保存： 保存完之后 ，执行以下命令 service network start 重启网卡。 重启网卡后 ，重新查询ip 执行命令 ip addr，下面红框中的是你的ip。 "},{"title":"centos7.8安装docker","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Centos/centos7.8%E5%AE%89%E8%A3%85docker/","tags":[["Centos","/tags/Centos/"]],"categories":[["Centos","/categories/Centos/"]],"content":"centos7.8安装docker引言 Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中,然后发布到任何流行的Linux机器或Windows 机器上,也可以实现虚拟化,容器是完全使用沙箱机制,相互之间不会有任何接口。–百度百科 简单来说作用，就是快速部署应用，统一运行环境，解决应用之间的隔离问题的作用，占用资源少。 步骤 Docker的三大核心概念：容器，镜像，仓库。它们之间的关系如下： Docker Web应用 容器 网站 镜像 源代码 仓库 Git仓库 准备的是centos7.8的新环境，下面进行安装： 设置好仓库： 进行默认安装： 安装完启动docker： 查看docker版本： "},{"title":"git如何把本地代码上传到Github","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Git/git%E5%A6%82%E4%BD%95%E6%8A%8A%E6%9C%AC%E5%9C%B0%E4%BB%A3%E7%A0%81%E4%B8%8A%E4%BC%A0%E5%88%B0Github/","tags":[["git","/tags/git/"]],"categories":[["Git","/categories/Git/"]],"content":"git如何把本地代码上传到Github步骤 安装好Git，官网下载。 安装的话自己搜索其他教程,我这里就不描述了。 点击右键Git Gash Here 进入到当前文件夹的命令行界面。注意是当前目录，我一般都是在www目录。 把代码上传到Github 要做一些Git的配置。 首先初始化项目目录 命令行 输入： 本地Git仓库和GitHub仓库之间的传输是通过SSH加密的，所以必须先让git生成SSH-key 再让github仓库认证你SSH-key 。 命令行 输入： 上面的操作直接Enter 默认就好，然后根据上面的路径找到id_rsa.pub这个文件用编辑器打开，拿到ssh-key。注意事项：后缀是.pub。 登录你的github 去到你的设置。 设置用户名： 设置用户邮箱： 配置ok之后，查看是否配置成功： 在github 上创建库，拿到库的地址。 先设置远程代码库origin： 把库上面的克隆下来： 修改或编辑或添加文件，再add到 git &#x2F;&#x2F;添加到提交文件队列中： 真实提交到本地仓库： 代码合并提交到线上仓库： "},{"title":"git的自动部署","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Git/git%E7%9A%84%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/","tags":[["git","/tags/git/"]],"categories":[["Git","/categories/Git/"]],"content":"git的自动部署引言 早些年就想用git来做一个简单的单机自动部署的，原理通过hook(钩子)操作。 步骤 创建运行项目的根目录，这个路径自己定： 进入到根目录： 克隆仓库到根目录： 设置权限： 切换到git仓库里面项目钩子配置目录里面： 生成post-receive文件： 添加以下内容： 保存，然后给这个文件添加新的权限： 注意 这个自动部署只适合单机部署，市面上已经有很多成熟的方案了，GitHub 的 WebHook，GitLab + Jenkins，Drone + Gogs，这些听说也很香。"},{"title":"Laravel+PHPUnit学习记录","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/PHP/Laravel+PHPUnit%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","tags":[["PHP","/tags/PHP/"],["Laravel","/tags/Laravel/"],["PHPUnit","/tags/PHPUnit/"]],"categories":[["PHP","/categories/PHP/"]],"content":"Laravel+PHPUnit学习记录引言 参考资料： - Laravel教程 - 文章里面部分函数例如: visit()，see()，高版本已废弃，高版本函数请参考：Laravel文档 - PHPUnit中文网 步骤 使用的Laravel6.0进行的测试，自带PHPUnit，注意: 测试类约定成俗的放在tests目录下面，测试文件以xxxTest.php为结尾，不写的话会被忽略跳过。 测试类里面的方法，必须含有test开头，不然会忽略。 tests目录下面有几个文件，ExampleTest.php是测试类demo，TestCase.php是一个引导文件用于在我们的测试中设置 Laravel 环境。 项目的根目录下有个phpunit.xml文件，这个是测试配置文件， 元素必须拥有 name 属性，可以有一个或多个 及 子元素，分别代表需要搜索测试的目录及元素。 启动测试命令（laravel有自带的测试demo，可以执行测试一下，不能直接执行phpunit和环境变量有关系）: 启动之后会有以下结果： 4 tests ：这里指的是一共执行四个方法。（配置里的所有测试类里面的方法） 10 assertions ：这里指的是执行了10个断言结果。 OK ：达到了执行预期结果。 FAILURES ：错误结果 PHPUnit介绍完了，开始进行手动测试，创建一个测试类： 打开BasicTest.php文件： 然后执行测试命令，就直接返回测试结果。这里描述的是大概原理，不详细讲解断言的所有方法，有需要的话就去：PHPUnit中文网 实践一个测试案例，在app的目录下面创建Box.php文件（用于逻辑测试）： 然后修改刚刚用命令生成的BasicTest.php文件： 执行测试命令，等等断言结果，别光复制，上面有注释断言的含义，可以自己进行条件替换测试，一个简单类的逻辑测试就到这里了，下面来做一个简单的web页面的测试。 之前提到过的tests&#x2F;Feature&#x2F;目录下面有个测试用的demo -&gt; ExampleTest.php 打开里面有个testBasicTest方法，然后在这个基础上面修改成以下： web这里大致逻辑也在代码上注释了，请求一个地址检查输出内容是否符合自己的预期。 这里再测试一个简单json接口，首先在&#x2F;routes&#x2F;wab.php添加一个路由： 在刚刚的ExampleTest.php上面添加以下函数： 简单的接口数据测试，就是这样了，要涉及到复杂操作的话，还是要认真多看文档，多动手写测试。 "},{"title":"array_merge和array+array的区别","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/PHP/array_merge%E5%92%8Carray+array%E7%9A%84%E5%8C%BA%E5%88%AB/","tags":[["PHP","/tags/PHP/"]],"categories":[["PHP","/categories/PHP/"]],"content":"array_merge和array+array的区别引言 想起最近水群，看到的一个问题，就是array_merge函数和array+array的合并方式有什么区别。 步骤 测试代码： 从以上结果得出，array_merge和array+array 在字符串的键值中，都可以合并数组，区别在于： array_merge相同字符串键名的情况下，后一个值会覆盖前一个值。 array+array相同字符串键名的情况下，会保留前一个值，放弃后一个值。 上面是键值作为字符串的数组，下面这里是用数值作为键值的数组: 6.从以上的结果得出： array_merge相同数值键名的情况下，函数将返回带有整数键名的新数组，其键名以 0 开始进行重新排序索引。 array+array相同数值键名的情况下，会保留前一个值，放弃后一个值。 总结 相同之处：可以合并数组。 不同之处: array_merge相同字符串键名的情况下，后一个值会覆盖前一个值。在数值键名的情况下，会返回一个新数组，从o开始的新索引。 array+array键名相同（字符串和数值）的情况下，会保留前一个值，放弃后一个值。 "},{"title":"Apache自带的ab压力测试工具使用","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/%E6%9D%82%E9%A1%B9/Apache%E8%87%AA%E5%B8%A6%E7%9A%84ab%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/","tags":[["apache","/tags/apache/"],["ab","/tags/ab/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"Apache自带的ab压力测试工具使用步骤 ab是Apache自带的压力测试工具，用于测试站点的承受能力，原名Apache Bench。 ab的原理是：创建多个并发进程，模拟多个用户同时对同一个目标网址发起访问。 使用方式，找到Apache的安装目录，有个bin文件夹，里面有一个ab.exe文件。比如我使用的phpstudy8.0。 在windows的命令行下(cmd)运行ab.exe，注意:直接双击ab.exe是无效的。 先打开cmd,比如以下快捷进入。 运行以下命令： 会出现如下的帮助界面： 红框中的是 ab的使用格式，例如(注意链接一定要&#x2F;结尾)： ab常用参数说明： -n ：总共的请求执行数； -c： 并发数，缺省是1； -t：测试所进行的总时间，秒为单位 -p：POST时的数据 -w: 以HTML表的格式输出结果 ab测试例子： 图片： ab测试的性能指标: 吞吐率（Requests per second）。概念：服务器并发处理能力的量化描述，单位是reqs&#x2F;s，指的是在某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。注意：吞吐率是基于并发用户数的，跟随用户数变化，数值表示当前机器的整体性能，值越大越好。 并发用户数（Concurrency Level）。 用户平均请求等待时间（Time per request）。用户等待时间参考2&#x2F;5&#x2F;8原则。 注意 注意测试服务器的时候要适量，ab会给测试对象带来压力，宕机别赖我啊。 "},{"title":"ElasticSearch在PHP中使用","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/%E6%9D%82%E9%A1%B9/ElasticSearch%E5%9C%A8PHP%E4%B8%AD%E4%BD%BF%E7%94%A8/","tags":[["ElasticSearch","/tags/ElasticSearch/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"ElasticSearch在PHP中使用引言 我测试用的例子是laravel6.0框架。 步骤 配置composer.json文件： 用composer进行安装： 安装完之后，随便新建一个控制，比如说index控制器，引入类库： 新建一个index方法，并在里面实例化客户端： 实例化完了，那就说说elasticsearch吧，es呢和数据库类似，所以一样会有增删查改的操作。 简单的示例代码： 注意 大致上的操作就是这样了，复杂的查询操作需要认真去看 深入搜索 这一章节。"},{"title":"ElasticSearch的windows基本安装运行","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/%E6%9D%82%E9%A1%B9/ElasticSearch%E7%9A%84windows%E5%9F%BA%E6%9C%AC%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C/","tags":[["ElasticSearch","/tags/ElasticSearch/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"ElasticSearch的windows基本安装运行引言 有些时候会遇到这么一个需求，就是一个搜索栏，需要能搜索出名称，地址，类型各式各样的关联数据，这个时候比较菜鸡的做法就是在搜索栏上面做一个分类选择，然后选择判断去做模糊搜索，要么就是直接名称OR地址OR类型模塑搜索，这个时候就很骚了。 早之前在技术群里面和博客里面有了解过ElasticSearch的大名，然而没有时间去实践到自己的项目里面，抽空开始搭建ElasticSearch的环境，了解的差不多就开始合并到项目里面去实践。 步骤 由于ElasticSearch（下面简称es）是java写的所以会依赖java的环境，java的jdk需要8或以上。 下载es的安装包：ElasticSearch官网 选择合适的环境包，比如我是window的环境： 正常起仓库名，不用xxx.github.io，访问的时候比较难看，而且下面创建博客建议使用同一个名字，比如blogName。 然后选择一个盘，解压出来： 进入bin目录，找到elasticsearch.bat文件，双击运行： 运行成功后：访问127.0.0.0:9200，然后出现以下数据就是运行成功了。 "},{"title":"JMeter使用-安装篇","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/%E6%9D%82%E9%A1%B9/JMeter%E4%BD%BF%E7%94%A8-%E5%AE%89%E8%A3%85%E7%AF%87/","tags":[["JMeter","/tags/JMeter/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"JMeter使用-安装篇引言 想起早期面试的时候，被人问到压力测试工具，回答到apache自带的ab工具还有java的JMeter。但实际上，我用的也少。特此记录一下。 步骤 先安装java的jdk,按照JMeter官网的说法，只能支持java8+的：官方下载 如下图（可能要注册一个账号，因为我下载的时候要求登录）： jdk在下载挺大的，接着下载最新的JMeter:官方下载 java的jdk下载好就安装，傻瓜包，安装好之后查看是否配置了环境变量。cmd输入以下命令： JMeter压缩包下载好后解压，找到bin目录下面的jmeter.bat文件。 打开jmeter.bat文件，然后按照一下步骤设置中文版： 这里就安装结束了。 "},{"title":"JMeter使用-简单测试篇","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/%E6%9D%82%E9%A1%B9/JMeter%E4%BD%BF%E7%94%A8-%E7%AE%80%E5%8D%95%E6%B5%8B%E8%AF%95%E7%AF%87/","tags":[["JMeter","/tags/JMeter/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"JMeter使用-简单测试篇步骤 添加线程组，如下图： 线程组可以配置线程数，准备时长等参数，如下图： 参数详解： 线程数：虚拟用户数，一个用户占用一个进程或线程。 Ramp-Up Period(in seconds)准备时长：设置的虚拟用户数需要多长时间全部启动。如果线程数为10，准备时长为2，那么需要2秒钟启动10个线程，也就是每秒钟启动5个线程。 循环次数：每个线程发送请求的次数。如果线程数为10，循环次数为100，那么每个线程发送100次请求。总请求数为10*100&#x3D;1000 。如果勾选了“永远”，那么所有线程会一直发送请求，一到选择停止运行脚本。 调度器：设置线程组启动的持续时间和启动延时时间。 添加http，如下图： 设置http请求，如下图： 参数详解： 协议：这里设置http&#x2F;https&#x2F;tcp等，根据自己需要填写。 服务器名：这里填写的是域名或ip。 端口号：这里默认80端口。 http请求方法：get，post，put，delete等都在这里设置。 路径：比如你请求接口的路径，不要加域名了。 内容编码：设置utf-8。 参数：这里可以设置你提交的参数 postman怎么用，这里也差不多。切记一点，提交中文的话一定要编码，在编码列打钩√。 添加观察结果树，可以查看每次http请求之后返回的结果，如下图： 参数详解： text栏目：这里查看请求。 取样器结果：这里显示请求后的返回结果。 添加聚合报告，如下图： 参数详解： Label：http请求都有一个 Name 属性，这里显示的就是 Name 属性的值。 样本（#Samples）：请求数——表示这次测试中一共发出了多少个请求，如果模拟10个用户，每个用户迭代10次，那么这里显示100。 平均数（Average）：平均响应时间——默认情况下是单个 Request 的平均响应时间，当使用了 Transaction Controller 时，以Transaction 为单位显示平均响应时间。 中位数（Median）： 50％ 用户的响应时间。 90%百分位（90% Line）：90％ 用户的响应时间。以此类推95%，99%。 最小值（Min）：最小响应时间。 最大值（Max）：最大响应时间。 异常（Error%）：错误请求数&#x2F;请求总数。 吞吐量（Throughput）：默认情况下表示每秒完成的请求数（Request per Second），当使用了 Transaction Controller 时，也可以表示类似 LoadRunner 的 Transaction per Second 数。 重点关注：1. Samples 请求数 2. Average 平均响应时间 3.Min 最小响应时间 4.Max 最大响应时间 5.Error% 异常率 6.Throughput 吞吐量。 开始测试，如下图: 简单测试到这里就结束了。有两个功能没有描述，我测试的是短信接口： 用户常量：顾明思义，用于测试不同的接口里面所需要的同一变量，比如user_id &#x3D;1 ，在查询用户资料或查询积分都会用上，为了避免重复填写或者改写多次。 断言：用于检查测试中得到的响应数据等是否符合预期，用以保证性能测试过程中的数据交互与预期一致。 "},{"title":"使用git客户端向git仓库提交文件","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Git/%E4%BD%BF%E7%94%A8git%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%90%91git%E4%BB%93%E5%BA%93%E6%8F%90%E4%BA%A4%E6%96%87%E4%BB%B6/","tags":[["git","/tags/git/"]],"categories":[["Git","/categories/Git/"]],"content":"使用git客户端向git仓库提交文件步骤 先克隆下来test文件夹。为什么叫test文件夹。详细看我之前的写的文章。 进入test文件夹。 设置 邮箱 用户名称 ，已经设置过的可以跳过。 查看有没有设置远程连接 origin ，一般来说克隆的时候会默认把链接设置成origin： 新建一个txt文件，随便建，加点内容。再执行以下： 提交到本地仓库。 获取远程库与本地同步合并（如果远程库不为空必须做这一步，否则后面的提交会失败）： 提交到线上的仓库： "},{"title":"在centos上搭建git仓库并克隆下来","date":"2023-09-04T16:00:00.000Z","url":"/2023/09/05/Git/%E5%9C%A8centos%E4%B8%8A%E6%90%AD%E5%BB%BAgit%E4%BB%93%E5%BA%93%E5%B9%B6%E5%85%8B%E9%9A%86%E4%B8%8B%E6%9D%A5/","tags":[["git","/tags/git/"]],"categories":[["Git","/categories/Git/"]],"content":"在centos上搭建git仓库并克隆下来步骤 公司需要，在服务器上面搭建一个git的代码仓库，然后写了这个记录。 自备服务器centos或者虚拟机（centos7.8）也行。 .查看git的版本号执行以下命令： 有安装的话，会返回版本号，没有安装出现以下错误。 执行以下命令，安装git。安装过的就跳过此步骤： 7.创建一个用户，用来管理git仓库。 做完以上操作，就开始创建代码仓库： 初始化裸仓库，注意加 —bare 和没加是有区别的： 参考文章：  这里代码仓库建好了，下面配置ssh： 编辑ssh配置文件： 重启sshd服务。 服务器端暂时结束。下面是客户端生成秘钥。 自己下载一个git的客户端，安装完后，打开Git Bash 执行以下命令。 生成的秘钥目录一般在C:\\Users\\Administrator.ssh 注意.pub后缀的是公钥。 导入公钥到服务器的&#x2F;home&#x2F;gitmaster&#x2F;.ssh&#x2F;authorized_keys文件里面： 注意：出现Are you sure you want to continue connecting (yes&#x2F;no)? 这句话的时候要手动输入yes，不能直接回车跳过。 导不进去？编辑authorized_keys文件，自己用编辑器打开本地的id_rsa.pub 复制进去保存。 最后一步 设置创建的git用户禁止ssh登录，有登录权限的记得干掉。 客户端克隆这个仓库。 出现下面这句是正解。 "},{"title":"Hexo 搭配 GitHub 建立博客","date":"2023-08-28T16:00:00.000Z","url":"/2023/08/29/%E6%9D%82%E9%A1%B9/Hexo%20%E6%90%AD%E9%85%8D%20GitHub%20%E5%BB%BA%E7%AB%8B%E5%8D%9A%E5%AE%A2/","tags":[["Hexo","/tags/Hexo/"],["github","/tags/github/"]],"categories":[["杂项","/categories/%E6%9D%82%E9%A1%B9/"]],"content":"Hexo 搭配 GitHub 建立博客引言 由于自己开的博客站经费不足嗝屁了，所以借用github搭建自己的个性博客。 步骤 本机安装nodejs和git，以及属于自己的github账号（硬性要求）。 登录gitbug，并且创建一个仓库，用于存放自己的Hexo博客。 创建过程参考（偷懒）：github创建仓库并设置github page 用xxx.github.io起名，xxx，是你的用户名 下面用 blogName替代。 打开命令行安装Hexo： 找个目录存放博客文件，我干PHP的所以我喜欢放在www目录，在www下打开命令行执行： 进入 blogName文件夹，并安装 Hexo 的依赖： 打开 Hexo 的配置文件 _config.yml，将 deploy 部分的 type 设置为 git，并将 repo 设置为您在第一步中创建的仓库的 URL，并且指定分支 branch: main。 这个URL是你仓库的地址，比如这样的： 里面还有一个url的配置,也是填写： title可以填写你的博客名。 到这里配置基本完成。 在命令行中运行以下命令，生成静态文件并部署到 GitHub Pages： 在浏览器中访问 xxxUserName.github.io，就可以看到 Hexo 博客了。 注意 xxxUserName是你的github账号名称。 每次更新博客内容后，都需要运行 hexo generate 和 hexo deploy 命令将更改部署到 GitHub Pages 上。 "}]